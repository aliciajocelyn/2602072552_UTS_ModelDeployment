# -*- coding: utf-8 -*-
"""2602072552_TrainingOOP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XH8YakF1t0BFhfdVj4RtNE1zdXvkKXwy
"""

### 2602072552_Alicia Jocelyn Siahaya_UTS_ModelDeployment
### OOP TRAINING CODE

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import StandardScaler

from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report
import pickle

class DataHandler:
    def __init__(self, file_path):
        self.file_path = file_path
        self.data = None
        self.input_df = None
        self_output_df = None

    def load_data(self):
        self.data = pd.read_csv(self.file_path)

    def create_input_output(self, target_column):
        self.output_df = self.data[target_column]
        self.input_df = self.data.drop(target_column, axis = 1)

    def data_head(self):
        return self.data.head()

    def data_info(self):
        self.data.info()

    def value_counts(self, cols):
        return self.data[cols].value_counts()

    def columns(self):
        return self.data.columns

    def dropColumns(self):
        self.data.drop(['Unnamed: 0', 'id', 'CustomerId', 'Surname'], axis = 1, inplace = True)

# Load Data
file_path = 'data_D.csv'
data_handler = DataHandler(file_path)
data_handler.load_data()
data_handler.dropColumns()
data_handler.create_input_output('churn')
input_df = data_handler.input_df
output_df = data_handler.output_df

class ModelHandler:
    def __init__(self, input_data, output_data):
        self.input_data = input_data
        self.output_data = output_data
        self.createModelRF()
        self.createModelXGB()
        self.x_train, self.x_test, self.y_train, self.y_test, self.y_predict = [None] * 5

    ## INFO DATA ##
    def infoTrainData(self):
        self.x_train.info()

    def infoTestData(self):
        self.x_test.info()

    def headTrainData(self):
        return self.x_train.head()

    ## IMPUTE DATA ##
    def fillNACreditScore(self):
      median = self.x_train['CreditScore'].median()
      self.x_train['CreditScore'].fillna(median, inplace = True)
      self.x_test['CreditScore'].fillna(median, inplace = True)

    ## SPLIT DATA ##
    def split_data(self, test_size=0.2, random_state=42):
        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.input_data, self.output_data, test_size=test_size, random_state=random_state)

    ## ENCODING ##
    def genderEncode(self):
      encode_gender = {"Gender": {"Male":1,"Female" :0}}
      self.x_train = self.x_train.replace(encode_gender)
      self.x_test = self.x_test.replace(encode_gender)

      filename = 'gender_encode.pkl'
      pickle.dump(encode_gender, open(filename, 'wb'))

    def geographyEncode(self):
      encode_geography = {'Geography': {"France":0, "Spain":1, "Germany":2}}
      self.x_train = self.x_train.replace(encode_geography)
      self.x_test = self.x_test.replace(encode_geography)

      filename = 'geography_encode.pkl'
      pickle.dump(encode_geography, open(filename, 'wb'))

    ## SCALING ##
    def scaling_CreditScore_Age(self):
      scaler1 = RobustScaler()
      scaler1.fit(self.x_train[['CreditScore', 'Age']])

      self.x_train[['CreditScore', 'Age']] = scaler1.transform(self.x_train[['CreditScore', 'Age']])
      self.x_test[['CreditScore', 'Age']] = scaler1.transform(self.x_test[['CreditScore', 'Age']])

      filename = 'robust_scaler.pkl'
      pickle.dump(scaler1, open(filename, 'wb'))

    def scaling_Tenure_Balance_EstSalary(self):
      scaler2 = StandardScaler()
      scaler2.fit(self.x_train[['Tenure', 'Balance', 'EstimatedSalary']])

      self.x_train[['Tenure', 'Balance', 'EstimatedSalary']] = scaler2.transform(self.x_train[['Tenure', 'Balance', 'EstimatedSalary']])
      self.x_test[['Tenure', 'Balance', 'EstimatedSalary']] = scaler2.transform(self.x_test[['Tenure', 'Balance', 'EstimatedSalary']])

      filename = 'standard_scaler.pkl'
      pickle.dump(scaler2, open(filename, 'wb'))

    ## MODELING ##
    ## RANDOM FOREST ##
    def createModelRF(self):
      self.modelRF = RandomForestClassifier()

    def trainModelRF(self):
      self.modelRF.fit(self.x_train, self.y_train)

    def makePredictionRF(self):
      self.y_predictRF = self.modelRF.predict(self.x_test)

    def evaluateModelRF(self):
      predictionsRF = self.modelRF.predict(self.x_test)
      return accuracy_score(self.y_test, predictionsRF)

    def createReportRF(self):
      print('\nClassification Report For Random Forest\n')
      print(classification_report(self.y_test, self.y_predictRF, target_names = ['0', '1']))

    def save_modelRF_to_pickle(self, filename):
      with open(filename,'wb') as file:
        pickle.dump(self.modelRF, file)

    ## XGBOOST ##
    def createModelXGB(self):
      self.modelXGB = xgb.XGBClassifier()

    def trainModelXGB(self):
      self.modelXGB.fit(self.x_train, self.y_train)

    def makePredictionXGB(self):
      self.y_predictXGB = self.modelXGB.predict(self.x_test)

    def evaluateModelXGB(self):
      predictionsXGB = self.modelXGB.predict(self.x_test)
      return accuracy_score(self.y_test, predictionsXGB)

    def createReportXGB(self):
      print('\nClassification Report For XGBoost\n')
      print(classification_report(self.y_test, self.y_predictXGB, target_names = ['0', '1']))

    ## SAVE TO PICKLE ##
    def save_modelXGB_to_pickle(self, filename):
      with open(filename,'wb') as file:
        pickle.dump(self.modelXGB, file)

model_handler = ModelHandler(input_df, output_df)
model_handler.split_data()

# PreProcessing
model_handler.fillNACreditScore()

model_handler.genderEncode()
model_handler.geographyEncode()

model_handler.scaling_CreditScore_Age()
model_handler.scaling_Tenure_Balance_EstSalary()

# model_handler.headTrainData()

# Model Random Forest
# model_handler.trainModelRF()
# model_handler.makePredictionRF()
# # print("Model Accuracy :", model_handler.evaluateModelRF())
# # model_handler.createReportRF()
# model_handler.save_modelRF_to_pickle("RF_model.pkl")

# Model XGBoost
model_handler.trainModelXGB()
model_handler.makePredictionXGB()
# print("Model Accuracy :", model_handler.evaluateModelXGB())
# model_handler.createReportXGB()

model_handler.save_modelXGB_to_pickle("XGB_model.pkl")